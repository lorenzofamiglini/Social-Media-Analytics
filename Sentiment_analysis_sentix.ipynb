{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment analysis su cluster 6, 9, 0, e bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Datasets/stream_tweets/Data/Bot_analysis/bot_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[df[\"cluster_y\"] == 9].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"text\"] != 'Scherzetto di @AMorelliMilano che domanda alle #sardine cosa ne pensano della frase (contenuta nel loro manifesto) \"..avete diritto di parola, ma non avete diritto di avere qualcuno che vi ascolti\", attribuendola per√≤ a #Salvini. Le risposte: fassista, antidemocr., tiranno <U+0001F602> https://t.co/Rfj06VT2tW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'@mentions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepml-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '@mentions'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-620-53e72e7f20a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"@mentions\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepml-gpu\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2994\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2995\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2996\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2997\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deepml-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '@mentions'"
     ]
    }
   ],
   "source": [
    "#app = df[\"@mentions\"].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = df[\"@mentions\"].reset_index()[\"@mentions\"].str.split(\",\",expand=True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app = app.melt(id_vars = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = app.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#app = app[app[\"value\"] == \"virginiaraggi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = app[\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra = df.iloc[indice,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_link(x):\n",
    "    x = re.sub(r\"http\\S+\", \"\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emoji(x):\n",
    "    x = re.sub(r\"(\\<U+\\S*>)\", \"\", x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = destra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df.text.str.lower()\n",
    "df.text = df.text.apply(remove_emoji)\n",
    "df[\"text\"] = df.text.apply(remove_link)\n",
    "df.text = df.text.replace(\"#\",\"\", regex = True) #rimozione hashtags \\w+\n",
    "df.text = df.text.replace(\"@[^\\s:]+\", \"\", regex = True) #rimozione mentions\n",
    "#df.text = df.text.replace(\"#\",\"\", regex = True)\n",
    "#df.text = df.text.replace(\"@\", \"\", regex = True)\n",
    "df.text = df.text.replace(\"\\n\", \" \", regex = True)\n",
    "df.text = df.text.replace(\"-\", \"\", regex = True)\n",
    "df.text = df.text.replace('[^\\w\\s]', ' ', regex = True)\n",
    "df.text = df.text.replace(\"_\", \"\", regex = True) \n",
    "df.text = df.text.replace(\"\\d*\",\"\",regex = True)\n",
    "df.text = df.text.replace('\\s+', ' ', regex=True) #rimuovere pi√π spazi bianchi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lex = pd.read_csv('D:/sentix.txt', sep=\"\\t\", header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "lex = lex.rename(columns = {0:\"lemma\",1:\"partofs\",2:\"id\",3:\"positive\",4:\"negative\", 5:\"polarity\", 6:\"intensity\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"it_core_news_sm\") #per l'italiano\n",
    "def map_nlp(x):\n",
    "    x = nlp(x)\n",
    "    return x\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_stop = [\"l\",\"c\",\"i\",\"eh\",\"fr\",\"e\",\"si\",\"no\",\"s\",\"o\",\"a\",\"u\",\"altre\",\"almeno\",\"so\",\"si\", \n",
    "             \" l\", \" l \", \" c \", \"e \", \" e \", \"s√¨\" ,\"oh\",\"ste\", \"√®\",\"ha\",\"ho\",\"sono\",\"abbiamo\",\n",
    "             \"avete\",\"siete\",\"hanno\",\"molte\",\"cose\",\"pure\", \"pur\", \"mah\",\"tante\",\"tanto\",\"altra\",\"piazza\",\"altri\",\"tanti\",\n",
    "             \"migliore\", \"d\", \"italia\",\"roma\",\"bella\",\"san\",\"giovanni\",\"piazze\", \n",
    "             \"salvini\",\"ovunque\",\"sardine\",\"gXiIzWheEt\",\"dicembre\",\"romanonabbocca\",\"romanonsilega\",\"sardinecontrosalvini\",\n",
    "              \"facciamorete\",\"piena\",\"jItzrfqmrs\",\"sysOW\",\"gapfill\",\"piene\",\"piazzasangiovanni\",\n",
    "             \"matteorenzi\",\"matteo\", \"meloni\",\"lega\",\"cisiamo\",\"torinononsilega\",\"sodovestare\",\"imola\",\n",
    "            \"sardina\",\"bellaciao\",\"ferrero\",\"adriano\",\"ciao\",\"nzingaretti\",\"test\",\"marte\",\"produzione\",\"sangiovanni\",\"santori\",\n",
    "             \"lastampa\",\"produz\",\"tac\",\"tic\",\"guzzanti\",\"casapound\",\"mattia\",\"pietro\",\"ahi\",\"amorellimilano\", \"ogongo\",\"n√®\",\n",
    "             \"capere\",\"frase\",\"renzi\",\"mattiasantori\",\"l√¨\",\"li\",\"repubblica\",\"nibras\",\"blob\",\"alto\",\"ilmessageroit\",\"ilmanifesto\",\n",
    "             \"tv\",\"eni\",\"tanto\", \"caro\",\"ben\",\"video\",\"giubileif\",\"tgpost\",\"n√©\",\"staseraitalia\",\"radiosavana\",\"santoro\",\"pago\",\n",
    "             \"capere\",\"mpskino\",\"unidicifr\",\"forl√¨\",\"eccolo\",\"vero\",\"sabato\",\"matteosalvinimi\",\"fqmillenium\",\"fattoquotidiano\",\n",
    "             \"gnela\",\"gliel\",\"sabato\",\"basilicata\",\"nonelarena\",\"staseraitalia\",\"mezzaorainpiu\",\"dire\",\"sott\",\n",
    "             \"solo\",\"s√®\",\"se\",\"s√©\",\"marcorizzopc\",\"tg\",\"rio\",\"fef\",\"ff\",\"f\",\"fb\",\"ffb\",\"fd\",\"ci√≤\",\"ce\",\"tiv√π\",\"fee\",\"twitter\",\n",
    "             \"dato\",\"facebook\",\"caro\",\"palco\",\"fe\",\"ny\",\"ctcf\",\"h\",\"pppasolini\",\"ah\",\"x\",\"pro\",\"zza\",\"qs\",\"ahhhhhhhhh\",\"de\",\"quello\",\"quella\",\"ve\",\n",
    "             \"ms\",\"m\",\"ahahahah\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lemma(x):\n",
    "    x = [token.lemma_ for token in x] #parole lemmatizzate\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in other_stop:\n",
    "    stopwords.add(i)\n",
    "stopwords.update(other_stop)\n",
    "\n",
    "for stopword in stopwords:\n",
    "    lexeme = nlp.vocab[stopword]\n",
    "    lexeme.is_stop = True\n",
    "    \n",
    "def remove_stopwords(x):\n",
    "    x = [token.lemma_ for token in x if not token.is_stop] #parole lemmatizzate\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra = df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra.text = destra.text.apply(map_nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (tante, belle, sardine, in, piazza, ad, ancona...\n",
       "1     (speriamo, che, le, sardine, non, si, dividano...\n",
       "2     (ecco, a, voi, le, famose, piazze, delle, sard...\n",
       "3     (dopo, settimane, intense, di, preparativi, si...\n",
       "4                                (sardine, a, cagliari)\n",
       "                            ...                        \n",
       "64    ( , romanonsilega, le, piazze, sono, di, tutti...\n",
       "65    ( , romanonsilega, verissimo, brescialecceadde...\n",
       "66    (grazie, per, aver, reso, roma, cos√¨, bella, p...\n",
       "67    (le, sardine, hanno, ottenuto, un, risultato, ...\n",
       "68          (amici, romanonsilega, verissimo, alimort√®)\n",
       "Name: text, Length: 69, dtype: object"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destra.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra.text = destra.text.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sperare', 'dividere', 'diverso', 'scatoletta', 'bancodisardine']"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destra.text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [bello, ancona, manifestare, lemarchenonsilega]\n",
       "1     [sperare, dividere, diverso, scatoletta, banco...\n",
       "2                          [famoso, linguaggio, odiare]\n",
       "3     [settimana, intenso, preparativo, riuscire, ra...\n",
       "4                                            [cagliari]\n",
       "                            ...                        \n",
       "64                                                  [ ]\n",
       "65    [ , verissimo, brescialecceadded, by, instagra...\n",
       "66    [rendere, passione, chiedere, politico, sano, ...\n",
       "67    [ottenere, risultare, politico, potere, mostra...\n",
       "68                         [amico, verissimo, alimort√®]\n",
       "Name: text, Length: 69, dtype: object"
      ]
     },
     "execution_count": 641,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destra.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_comma(x):\n",
    "    filtered = [i for i in x if i.strip()]\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "destra.text = destra.text.apply(remove_comma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = destra.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcolo polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "punteggio = []\n",
    "massimo = 0\n",
    "massimo_1 = []\n",
    "conta_neu = 0\n",
    "ind = []\n",
    "conta = 0\n",
    "conta_neg =0\n",
    "testo = []\n",
    "for i in indice:\n",
    "    try:\n",
    "        media = pd.merge(pd.DataFrame(destra.text.loc[i]),lex, \n",
    "                 left_on = 0, right_on = \"lemma\", how = \"inner\")\\\n",
    "                .groupby(\"lemma\")[[\"polarity\"]].min().reset_index()[\"polarity\"].mean()\n",
    "        punteggio.append(media)\n",
    "        if media > 0:\n",
    "            conta = conta + 1\n",
    "        if media < 0:\n",
    "            conta_neg = conta_neg + 1\n",
    "        if media == 0:\n",
    "            conta_neu = conta_neu + 1\n",
    "        if massimo >= media:\n",
    "            massimo_1.append(media)\n",
    "            testo.append(destra.text.loc[i])\n",
    "            ind.append(i)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.13467188455009943"
      ]
     },
     "execution_count": 656,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(punteggio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"D:/Datasets/stream_tweets/Data/Bot_analysis/bot_dataset.csv\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df2[df2[\"cluster_y\"] == 9].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2[\"text\"] != 'Scherzetto di @AMorelliMilano che domanda alle #sardine cosa ne pensano della frase (contenuta nel loro manifesto) \"..avete diritto di parola, ma non avete diritto di avere qualcuno che vi ascolti\", attribuendola per√≤ a #Salvini. Le risposte: fassista, antidemocr., tiranno <U+0001F602> https://t.co/Rfj06VT2tW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pretendiamo dalle sardine risposte che non possono dare. non sono nate per questo. sono la gigantesca domanda di un‚Äôaltra politica. sono un no finalmente urlato al razzismo, alla grettezza, al qualunquismo. una domanda e un no che la politica farebbe bene ad ascoltare #sardine'"
      ]
     },
     "execution_count": 692,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.loc[21]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
